
# I. INTRODUCCIÓN

### 1.1. Motivación

En la era actual, marcada por los rápidos y constantes avances tecnológicos, nos encontramos inmersos en un panorama donde los dispositivos electrónicos no solo son más abundantes, sino también más sofisticados. Esta evolución tecnológica está produciendo un incremento exponencial en la generación y consumo de contenido multimedia, particularmente en imágenes y vídeos.

Este crecimiento masivo ha dado lugar al aumento del uso de bases de datos que albergan una inmensa cantidad de contenido visual, abarcando desde fotografías cotidianas hasta producciones cinematográficas de alta definición. En este contexto surge la necesidad de desarrollar sistemas de recuperación de información que se basen en el contenido visual de estos medios, con el fin de facilitar la búsqueda y acceso a la información de manera ágil, eficaz y eficiente.

Si bien es cierto que en la actualidad existen propuestas comerciales como Google Images, que permiten la recuperación de imágenes mediante algoritmos de búsqueda textual y de contenido visual, es importante destacar que la mayoría de estos sistemas se centran principalmente en la recuperación de imágenes estáticas. Sin embargo, el desafío radica en el desarrollo de soluciones igualmente eficaces para la recuperación de contenido de vídeo, una tarea que aún no ha sido abordada de manera extendida en el ámbito comercial. Esto se puede probar con un sencillo ejemplo: Si procedemos a realizar una búsqueda en Google, tendremos 3 posibles alternativas. La primera y más extendida es la búsqueda por texto, donde los usuarios escriben palabras clave o frases para obtener resultados relevantes. La segunda es la búsqueda por voz y se basa en el reconocimiento de voces, transcribiendo el mensaje que recibe por el micrófono para realizar búsquedas por texto (por lo que se podría considerar una extensión de la búsqueda por texto). Por último, la búsqueda por imagen permite a los usuarios subir una imagen o tomar una foto para encontrar información relacionada. 

Sin embargo, a día de hoy se carece de una opción para introducir un vídeo y obtener resultados relevantes basados en su contenido. Si se da el caso en el que tengamos un vídeo que muestre objetos, lugares o productos que no se pueden describir fácilmente con palabras, no existe la posibilidad de buscar contenido relacionado. Incluso aún pudiendo describir el contenido que se quiere mostrar, los resultados que se obtienen pueden diferir mucho de los deseados. A continuación se plantea una hipotética situación en la que queremos visualizar vídeos que muestren una regadera amarilla. Google realiza las búsquedas basándose principalmente (y entre otras muchas cosas) en las palabras que componen el título del vídeo, ignorando por completo el contenido de este. A esto se suma las diferencias dialécticas, que pueden complicar aún más las búsquedas (en América Latina, la palabra regadera puede referirse a una ducha). Es por ello que los resultados obtenidos son completamente diferentes a los que se esperan obtener, como puede observarse en la siguiente figura. El objetivo de este proyecto será solventar este problema y desarrollar una aplicación que permita realizar búsquedas basadas en contenido.

El vídeo, como forma de expresión y comunicación, presenta una serie de desafíos adicionales en comparación con las imágenes estáticas. La información contenida en un vídeo no se limita únicamente a los fotogramas individuales, sino que también abarca elementos temporales, como la secuencia de imágenes, el movimiento, el audio y otros aspectos dinámicos. Por lo tanto, el diseño de sistemas de recuperación de información para contenido de vídeo implica una complejidad adicional en la captura y búsqueda de contenido relevante.
A pesar de los avances significativos en el campo de la inteligencia artificial y el procesamiento de contenido, aún queda un largo camino por recorrer para alcanzar soluciones robustas en la recuperación de contenido de vídeo.



### 1.2. Objetivos

El objetivo del proyecto se centra en la expansión y adaptación de modelos relevantes para la descripción de imágenes al contexto del vídeo, empleando técnicas de segmentación que permitan el análisis de escenas de manera individualizada. En este contexto, el propósito general es desarrollar módulos integrados en el marco de la JMR (Java Multimedia Retrieval©) para la descripción de vídeos, así como métricas que permitan la realización de consultas basadas en dichos descriptores visuales.

Para alcanzar este propósito general, se han establecido una serie de objetivos específicos:

- Análisis de soluciones para la segmentación de vídeo y extracción de escenas: Se llevará a cabo una revisión exhaustiva de las soluciones existentes en el ámbito de la segmentación de vídeo, con el fin de identificar las metodologías más adecuadas para la extracción de escenas. Este análisis incluirá la evaluación de algoritmos y técnicas utilizadas en la segmentación de vídeos, considerando factores como la eficiencia computacional y la precisión en la identificación de escenas relevantes, también llamadas keyscenes, y representadas por sus correspondientes keyframes.

- Desarrollo de descriptores visuales para vídeo basados en contenido: Se procederá al diseño y desarrollo de descriptores visuales específicamente adaptados para el análisis de contenido en vídeos. Estos descriptores deberán capturar características estructurales de las escenas, permitiendo una representación eficaz del contenido visual mostrado en el vídeo. 

- Integración de los descriptores desarrollados en la biblioteca JMR (Java Multimedia Retrieval©) de software libre: Se trabajará en la integración de los descriptores visuales desarrollados en el marco de la biblioteca JMR. Esta integración facilitará la utilización y adaptación de dichos descriptores con el resto de componentes de la biblioteca.

- Implementación de un prototipo CBIR de recuperación de vídeo basado en lo desarrollado para los objetivos anteriores: Se llevará a cabo la implementación de un prototipo de sistema de recuperación de información basado en contenido visual (CBIR) para vídeos, haciendo uso de los descriptores visuales y las métricas desarrolladas en los objetivos anteriores. Este prototipo permitirá realizar consultas de búsqueda de vídeos similares a partir de características visuales específicas, demostrando la eficacia y la utilidad práctica de los módulos desarrollados en el proyecto.

En resumen, el proyecto tiene como objetivo principal avanzar en el campo de la descripción y recuperación de información en vídeos, mediante el desarrollo de técnicas y herramientas innovadoras que permitan analizar, representar y buscar contenido visual de manera eficiente y efectiva. La consecución de estos objetivos permitirá la ampliación de las posibilidades de exploración y manipulación de contenido audiovisual en diversos contextos y sectores.
